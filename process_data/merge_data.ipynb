{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '004539375',\n",
       "  'image': '00453/004539375.jpg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': 'Render a clear and concise summary of the photo.\\n<image>'},\n",
       "   {'from': 'gpt',\n",
       "    'value': 'select luxury furniture 3 - inch gel memory foam mattress topper'}]},\n",
       " {'id': '002239345',\n",
       "  'image': '00223/002239345.jpg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': 'Write a terse but informative summary of the picture.\\n<image>'},\n",
       "   {'from': 'gpt', 'value': 'a grey watch with an army style strap'}]}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "# with open(\"/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json\", \"r\") as f:\n",
    "#     data = json.load(f)\n",
    "# data[:2]\n",
    "with open(\"/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-Pretrain/blip_laion_cc_sbu_558k.json\", 'r') as f:  \n",
    "    data = json.load(f)  \n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '000000010',\n",
       "  'image': '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_images/000000010.jpg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nPlease generate detailed descriptions of the given image.'},\n",
       "   {'from': 'gpt',\n",
       "    'value': 'The image shows a scene of a significant vehicle accident. A white car is severely damaged, with its body crumpled and parts of the vehicle scattered around. The car appears to have been involved in a high-speed impact, as suggested by the extensive damage and the disarray of the surrounding area.\\n\\nIn the foreground, there is a person wearing a high-visibility vest, which is typically worn by emergency personnel or workers to ensure they are easily seen in such situations. This individual is standing near the wreckage, possibly assessing the situation or preparing to provide assistance.\\n\\nThe setting appears to be an outdoor area with grass, and there are various items scattered around, including what looks like a suitcase and other debris, indicating that the accident may have occurred in a public space or near a parking area.\\n\\nIn the background, there is a sign with the word \"Reliant\" on it, which could be part of a larger sign or structure, possibly indicating the name of a nearby establishment or facility. The sign is partially obscured by the debris from the accident.\\n\\nThe overall scene suggests a serious incident that has likely attracted the attention of emergency services and possibly led to disruption in the area. The image captures the immediate aftermath of the accident, with no visible people other than the individual in the high-visibility vest.'}],\n",
       "  'data_source': 'llava-recap-558K'},\n",
       " {'id': '000000012',\n",
       "  'image': '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_images/000000012.jpg',\n",
       "  'conversations': [{'from': 'human',\n",
       "    'value': '<image>\\nPlease generate detailed descriptions of the given image.'},\n",
       "   {'from': 'gpt',\n",
       "    'value': 'The image shows a light blue baby onesie laid out flat against a white background. The onesie has short sleeves and a snap button closure at the front, which is typical for baby clothing to allow for easy dressing and undressing. On the front of the onesie, there is a text design in a bold, sans-serif font. The text reads \"Antoni& Bobby& Jonathan& Karamo& Tan.\" The text is arranged in a horizontal line, with each name separated by an ampersand. The style of the image is a straightforward product display, intended to showcase the design and color of the onesie.'}],\n",
       "  'data_source': 'llava-recap-558K'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取到的 JSON 路径:\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-118K/coco118k_stage1.5_finetune_w_prompt_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-CC3M/cc3m_recap_data_prompt_v2_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/ureader_tr/ureader_tr_processed_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/evol_instruct/evol_instruct_processed.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_zh/synthdog_zh_processed_abs.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_en/synthdog_en_processed_abspath.json\n"
     ]
    }
   ],
   "source": [
    "import yaml  \n",
    "  \n",
    "# 定义 YAML 文件的路径  \n",
    "yaml_file_path = \"/home/v-lingjiang/project/LLaVa_NeXT/scripts/train/mid_stage_mypath.yaml\"  \n",
    "  \n",
    "# 读取 YAML 文件  \n",
    "try:  \n",
    "    with open(yaml_file_path, \"r\", encoding=\"utf-8\") as file:  \n",
    "        yaml_data = yaml.safe_load(file)  \n",
    "except Exception as e:  \n",
    "    print(f\"读取 YAML 文件时出错: {e}\")  \n",
    "    exit(1)  \n",
    "  \n",
    "# 提取 json_path 信息  \n",
    "json_paths = []  \n",
    "datasets = yaml_data.get('datasets', [])  \n",
    "for dataset in datasets:  \n",
    "    json_path = dataset.get('json_path')  \n",
    "    if json_path:  \n",
    "        json_paths.append(json_path)  \n",
    "  \n",
    "# 输出所有 json_path  \n",
    "print(\"提取到的 JSON 路径:\")  \n",
    "for path in json_paths:  \n",
    "    print(path)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json',\n",
       " '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-118K/coco118k_stage1.5_finetune_w_prompt_abspath.json',\n",
       " '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-CC3M/cc3m_recap_data_prompt_v2_abspath.json',\n",
       " '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/ureader_tr/ureader_tr_processed_abspath.json',\n",
       " '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/evol_instruct/evol_instruct_processed.json',\n",
       " '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_zh/synthdog_zh_processed_abs.json',\n",
       " '/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_en/synthdog_en_processed_abspath.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  \n",
    "  \n",
    "# 读取原始数据  \n",
    "with open('/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json', 'r') as f:  \n",
    "    data = json.load(f)  \n",
    "  \n",
    "# 定义转换函数  \n",
    "def convert_conversations_to_messages(data):  \n",
    "    for item in data:  \n",
    "        messages = []  \n",
    "        for conversation in item['conversations']:  \n",
    "            role = 'user' if conversation['from'] == 'human' else 'assistant'  \n",
    "            # 确保 <image> 在消息的开头  \n",
    "            content = conversation['value']  \n",
    "            if '<image>' in content:  \n",
    "                content = '<image>' + content.replace('<image>', '').strip()  \n",
    "            messages.append({  \n",
    "                \"content\": content,  \n",
    "                \"role\": role  \n",
    "            })  \n",
    "        # 用新格式替换旧的 conversations  \n",
    "        item['messages'] = messages  \n",
    "        item['images'] = [item.pop('image')]  \n",
    "        del item['conversations']  \n",
    "    return data  \n",
    "  \n",
    "# 执行转换  \n",
    "new_data = convert_conversations_to_messages(data)  \n",
    "  \n",
    "# # 打印转换后的前两个数据以验证结果  \n",
    "# print(json.dumps(new_data[:2], indent=2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取到的 JSON 路径:\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-118K/coco118k_stage1.5_finetune_w_prompt_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-CC3M/cc3m_recap_data_prompt_v2_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/ureader_tr/ureader_tr_processed_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/evol_instruct/evol_instruct_processed.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_zh/synthdog_zh_processed_abs.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_en/synthdog_en_processed_abspath.json\n",
      "处理文件 /mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/evol_instruct/evol_instruct_processed.json 时出错: 'image'\n",
      "数据成功写入 /mnt/lingjiejiang/multimodal_code/data/llava_code_data/llava_ov_mid_all.jsonl\n"
     ]
    }
   ],
   "source": [
    "import yaml  \n",
    "import json  \n",
    "  \n",
    "# 定义 YAML 文件的路径  \n",
    "yaml_file_path = \"/home/v-lingjiang/project/LLaVa_NeXT/scripts/train/mid_stage_mypath_filter.yaml\"  \n",
    "  \n",
    "# 读取 YAML 文件  \n",
    "try:  \n",
    "    with open(yaml_file_path, \"r\", encoding=\"utf-8\") as file:  \n",
    "        yaml_data = yaml.safe_load(file)  \n",
    "except Exception as e:  \n",
    "    print(f\"读取 YAML 文件时出错: {e}\")  \n",
    "    exit(1)  \n",
    "  \n",
    "# 提取 json_path 信息  \n",
    "json_paths = []  \n",
    "datasets = yaml_data.get('datasets', [])  \n",
    "for dataset in datasets:  \n",
    "    json_path = dataset.get('json_path')  \n",
    "    if json_path:  \n",
    "        json_paths.append(json_path)  \n",
    "  \n",
    "# 输出所有 json_path  \n",
    "print(\"提取到的 JSON 路径:\")  \n",
    "for path in json_paths:  \n",
    "    print(path)  \n",
    "  \n",
    "# 定义转换函数  \n",
    "def convert_conversations_to_messages(data):  \n",
    "    for item in data:  \n",
    "        messages = []  \n",
    "        for conversation in item['conversations']:  \n",
    "            role = 'user' if conversation['from'] == 'human' else 'assistant'  \n",
    "            # 确保 <image> 在消息的开头  \n",
    "            content = conversation['value']  \n",
    "            if '<image>' in content:  \n",
    "                content = '<image>' + content.replace('<image>', '').strip()  \n",
    "            messages.append({  \n",
    "                \"content\": content,  \n",
    "                \"role\": role  \n",
    "            })  \n",
    "        # 用新格式替换旧的 conversations  \n",
    "        item['messages'] = messages  \n",
    "        item['images'] = [item.pop('image')]  \n",
    "        del item['conversations']  \n",
    "    return data  \n",
    "  \n",
    "# 合并所有数据  \n",
    "all_data = []  \n",
    "  \n",
    "for json_path in json_paths:  \n",
    "    try:  \n",
    "        with open(json_path, 'r', encoding='utf-8') as f:  \n",
    "            data = json.load(f)  \n",
    "            converted_data = convert_conversations_to_messages(data)  \n",
    "            all_data.extend(converted_data)  \n",
    "    except Exception as e:  \n",
    "        print(f\"处理文件 {json_path} 时出错: {e}\")  \n",
    "  \n",
    "# 写入到 JSONL 文件  \n",
    "output_file_path = '/mnt/lingjiejiang/multimodal_code/data/llava_code_data/llava_ov_mid_all.jsonl'  \n",
    "try:  \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:  \n",
    "        for item in all_data:  \n",
    "            json_line = json.dumps(item, ensure_ascii=False)  \n",
    "            f.write(json_line + '\\n')  \n",
    "    print(f\"数据成功写入 {output_file_path}\")  \n",
    "except Exception as e:  \n",
    "    print(f\"写入 JSONL 文件时出错: {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "提取到的 JSON 路径:\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_stage1.5_finetune_w_prompt_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-118K/coco118k_stage1.5_finetune_w_prompt_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-CC3M/cc3m_recap_data_prompt_v2_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/ureader_tr/ureader_tr_processed_abspath.json\n",
      "/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-OneVision-Mid-Data/synthdog_en/synthdog_en_processed_abspath.json\n",
      "数据成功写入 /mnt/lingjiejiang/multimodal_code/data/llava_code_data/llava_ov_mid_all_filter_noimage_en.jsonl\n"
     ]
    }
   ],
   "source": [
    "import yaml  \n",
    "import json  \n",
    "  \n",
    "# 定义 YAML 文件的路径  \n",
    "yaml_file_path = \"/home/v-lingjiang/project/LLaVa_NeXT/scripts/train/mid_stage_mypath_filter.yaml\"  \n",
    "  \n",
    "# 读取 YAML 文件  \n",
    "try:  \n",
    "    with open(yaml_file_path, \"r\", encoding=\"utf-8\") as file:  \n",
    "        yaml_data = yaml.safe_load(file)  \n",
    "except Exception as e:  \n",
    "    print(f\"读取 YAML 文件时出错: {e}\")  \n",
    "    exit(1)  \n",
    "  \n",
    "# 提取 json_path 信息  \n",
    "json_paths = []  \n",
    "datasets = yaml_data.get('datasets', [])  \n",
    "for dataset in datasets:  \n",
    "    json_path = dataset.get('json_path')  \n",
    "    if json_path:  \n",
    "        json_paths.append(json_path)  \n",
    "  \n",
    "# 输出所有 json_path  \n",
    "print(\"提取到的 JSON 路径:\")  \n",
    "for path in json_paths:  \n",
    "    print(path)  \n",
    "  \n",
    "# 定义转换函数  \n",
    "def convert_conversations_to_messages(data):  \n",
    "    filtered_data = []  \n",
    "    for item in data:  \n",
    "        if 'image' not in item or not item['image']:  \n",
    "            continue  # 跳过不包含 image 字段或 image 为空的项  \n",
    "        messages = []  \n",
    "        for conversation in item['conversations']:  \n",
    "            role = 'user' if conversation['from'] == 'human' else 'assistant'  \n",
    "            # 确保 <image> 在消息的开头  \n",
    "            content = conversation['value']  \n",
    "            if '<image>' in content:  \n",
    "                content = '<image>' + content.replace('<image>', '').strip()  \n",
    "            messages.append({  \n",
    "                \"content\": content,  \n",
    "                \"role\": role  \n",
    "            })  \n",
    "        # 用新格式替换旧的 conversations  \n",
    "        item['messages'] = messages  \n",
    "        item['images'] = [item.pop('image')]  \n",
    "        del item['conversations']  \n",
    "        filtered_data.append(item)  \n",
    "    return filtered_data  \n",
    "  \n",
    "# 合并所有数据  \n",
    "all_data = []  \n",
    "  \n",
    "for json_path in json_paths:  \n",
    "    try:  \n",
    "        with open(json_path, 'r', encoding='utf-8') as f:  \n",
    "            data = json.load(f)  \n",
    "            converted_data = convert_conversations_to_messages(data)  \n",
    "            all_data.extend(converted_data)  \n",
    "    except Exception as e:  \n",
    "        print(f\"处理文件 {json_path} 时出错: {e}\")  \n",
    "  \n",
    "# 写入到 JSONL 文件  \n",
    "output_file_path = '/mnt/lingjiejiang/multimodal_code/data/llava_code_data/llava_ov_mid_all_filter_noimage_en.jsonl'  \n",
    "try:  \n",
    "    with open(output_file_path, 'w', encoding='utf-8') as f:  \n",
    "        for item in all_data:  \n",
    "            json_line = json.dumps(item, ensure_ascii=False)  \n",
    "            f.write(json_line + '\\n')  \n",
    "    print(f\"数据成功写入 {output_file_path}\")  \n",
    "except Exception as e:  \n",
    "    print(f\"写入 JSONL 文件时出错: {e}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3735887"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '000000010',\n",
       "  'data_source': 'llava-recap-558K',\n",
       "  'messages': [{'content': '<image>Please generate detailed descriptions of the given image.',\n",
       "    'role': 'user'},\n",
       "   {'content': 'The image shows a scene of a significant vehicle accident. A white car is severely damaged, with its body crumpled and parts of the vehicle scattered around. The car appears to have been involved in a high-speed impact, as suggested by the extensive damage and the disarray of the surrounding area.\\n\\nIn the foreground, there is a person wearing a high-visibility vest, which is typically worn by emergency personnel or workers to ensure they are easily seen in such situations. This individual is standing near the wreckage, possibly assessing the situation or preparing to provide assistance.\\n\\nThe setting appears to be an outdoor area with grass, and there are various items scattered around, including what looks like a suitcase and other debris, indicating that the accident may have occurred in a public space or near a parking area.\\n\\nIn the background, there is a sign with the word \"Reliant\" on it, which could be part of a larger sign or structure, possibly indicating the name of a nearby establishment or facility. The sign is partially obscured by the debris from the accident.\\n\\nThe overall scene suggests a serious incident that has likely attracted the attention of emergency services and possibly led to disruption in the area. The image captures the immediate aftermath of the accident, with no visible people other than the individual in the high-visibility vest.',\n",
       "    'role': 'assistant'}],\n",
       "  'images': ['/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_images/000000010.jpg']},\n",
       " {'id': '000000012',\n",
       "  'data_source': 'llava-recap-558K',\n",
       "  'messages': [{'content': '<image>Please generate detailed descriptions of the given image.',\n",
       "    'role': 'user'},\n",
       "   {'content': 'The image shows a light blue baby onesie laid out flat against a white background. The onesie has short sleeves and a snap button closure at the front, which is typical for baby clothing to allow for easy dressing and undressing. On the front of the onesie, there is a text design in a bold, sans-serif font. The text reads \"Antoni& Bobby& Jonathan& Karamo& Tan.\" The text is arranged in a horizontal line, with each name separated by an ampersand. The style of the image is a straightforward product display, intended to showcase the design and color of the onesie.',\n",
       "    'role': 'assistant'}],\n",
       "  'images': ['/mnt/lingjiejiang/multimodal_code/data/llava_onevision/LLaVA-ReCap-558K/blip558k_images/000000012.jpg']}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3835887"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
